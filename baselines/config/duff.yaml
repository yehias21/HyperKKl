credentials: /media/yehias21/DATA/projects/KKL observer/hyperkkl/baselines/config/credentials.yaml
dirs:
  data: ${hydra:run.dir}
  logs: ${hydra:runtime.cwd}/logs
  models: ${hydra:runtime.cwd}/models

data:

  solver:
    _target_: src.simulators.solvers.get_solver
    name: rk4
  PINN_sample_mode: split_set # split_set, split_time, same
  data_gen_mode: backward_sim #forward_sim, backward_sim
  dataloader:
    seed: 123
    batch_size: 32
    validation: 10 # time in sec
    shuffle: True
    window_size: 1

  sim_time:
    _target_: src.simulators.types.SimTime
    t0: 0.0 # in seconds
    tn: 10.0  # in seconds (including validation time)
    eps: 0.001 #  Make sure to take the Shannon's theorem into account


  system:
    _target_: src.simulators.system.Duffing
    num_samples: 1
    system_param:
        _target_: src.simulators.types.SysParam
        C: [1, 0] # Observation matrix
        ObservableIndex: [0]
    sampler:
      _target_: src.simulators.sampler.get_sampler
      sampler_type: lhs
      seed: 123
      sample_space: [[ -1,1 ],[ -1,1 ]]


  input_signal:
    _target_: src.simulators.system.SinSignal
    num_samples: 1
    sig_param:
      _target_: src.simulators.types.SigParam
      signal_type: harmonics
      signal_data:
        {
          amp: [ 1, 3, 4, 5 ],
          freq: [ 1, 3, 6, 2 ],
          phase: [ 0, 0, 0, 0 ]
        }
    sampler:
      _target_: src.simulators.sampler.get_sampler
      sampler_type: lhs
      seed: 123
      sample_space: [[-1,1]]


  observer:
      _target_: src.simulators.system.Observer
      A: [-6.5549,  4.6082, -5.2057, 3.3942, 6.0211,
          -10.9772, -2.3362, -3.7164, -3.9566, -3.7166,
          -1.9393, -0.2797, -2.7983, -0.8606, -4.8050,
          -10.5100, -1.0820, -2.6448, -2.1144, -7.0080,
          -10.1003, -0.5111, 1.0275, 3.1996, -0.3463]
      B: [1.0, 1.0, 1.0, 1.0, 1.0]
      z_dim: 5
      e: 0.000001 #10e-6
      z_max: 10
      num_samples: 1
      sampler:
        _target_: src.simulators.sampler.get_sampler
        sampler_type: uniform
        seed: 123
        sample_space: [[ -1,1 ],[ -1,1 ],[ -1,1 ],[ -1,1 ],[ -1,1 ]]

models:

  forward_mapper:
    type: MLP
    update_method: full #backprop, delta, full
    input_size: 2
    output_size: 5
    hidden_dim: [ 100, 100, 100 ]
    activation: [ relu, relu, relu ]
    pretrained: False

  inverse_mapper:
    type: MLP
    update_method: backprop #backprop, delta, full
    input_size: 5
    output_size: 2
    hidden_dim: [ 100, 100, 100 ]
    activation: [ relu, relu, relu ]
    pretrained: False

  hypernetwork:
    shared: True
    encoder:
      type: MLP
      update_method: backprop
      input_size: 1
      output_size: 128
      hidden_dim: [ 100, 100, 100 ]
      activation: [ relu, relu, relu ]
    decoder:
      method: lora #Full, chunked, lora
      regress: weight  #all - weight
      input_size: 128
      rank_ratio: 0.5

trainer:
  method: supervised    #or unsupervised
  epochs: 15
  learning_rate: 0.001
  lambda: 1
